Assignment 2: Implementing Feedforward Neural Networks with Keras and TensorFlow ðŸ§  Implement a feedforward neural network using Keras and TensorFlow.

a. Import the necessary packages. ðŸ“¦ b. Load the training and testing data (MNIST/CIFAR10). ðŸ“‚ c. Define the network architecture using Keras. ðŸ§® d. Train the model using SGD. ðŸš€ e. Evaluate the network. ðŸ“Š f. Plot the training loss and accuracy. ðŸ“ˆ


import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.datasets import mnist


(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()


#shape of numpy arrays
print(f"Shape of X_train {x_train.shape}")
print(f"Shape of y_train {y_train.shape}")
print(f"Shape of x_test  {x_test.shape}")
print(f"Shape of y_test  {y_test.shape}")
# x_train( 60k images of 28*28 dimention) Pixel values range from 0 to 255.
# y_train: digit labels (integers in range 0-9)



#displaying the image
plt.imshow(x_train[25])
plt.show()

#printing corresponding label
print(y_train[25])




#unique values in Y_rain
print(np.unique(y_train))
print(np.unique(y_test))


#scaling the values
x_train = x_train/255
x_test = x_test/255
# 0/255 = 255
#255/255 = 1 maximum value
print(x_train.shape, x_test.shape)



model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(50,activation='relu',name='L1'),
    keras.layers.Dense(50,activation='relu',name='L2'),
    keras.layers.Dense(10,activation='softmax',name='L3')
])



model.compile(optimizer="sgd",loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

# Training the model
history = model.fit(x_train, y_train,
              batch_size=30,
              epochs=10,
              validation_data=(x_test, y_test),
              shuffle=True)

# Evaluating the model
loss,accuracy = model.evaluate(x_test,y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

# Plotting the Model Accuracy & Model Loss vs Epochs
plt.figure(figsize=[15,8])

# summarize history for accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy', size=25, pad=20)
plt.ylabel('Accuracy', size=15)
plt.xlabel('Epoch', size=15)
plt.legend(['train', 'test'], loc='upper left')


# summarize history for loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss', size=25, pad=20)
plt.ylabel('Loss', size=15)
plt.xlabel('Epoch', size=15)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Display an example image from x_test and its predicted label
plt.imshow(x_test[15])
plt.show()

# Predicting the value
predicted_value = model.predict(x_test)
print("Predicted Label:", np.argmax(predicted_value[15], axis=0))